<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>SURF Project Introduction Presentation</title>

        <link rel="stylesheet" href="dist/reset.css">
        <link rel="stylesheet" href="dist/reveal.css">
        <link rel="stylesheet" href="dist/theme/black.css"> <!-- Using the black theme as base -->

        <!-- Theme used for syntax highlighted code -->
        <link rel="stylesheet" href="plugin/highlight/monokai.css">

        <!-- Include Raleway font from Google Fonts -->
        <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@400;700&display=swap" rel="stylesheet">

        <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
        <style>
            body {
                font-family: 'Raleway', sans-serif;
            }
            .reveal {
                position: relative;
                z-index: 1; /* Higher than particles-js */
            }
            .reveal .slides section {
                background-color: transparent; /* Ensure slides are transparent */
                color: white; /* Ensuring text is visible over particles */
                text-align: left; /* Left-align the text */
            }
            .reveal h1, .reveal h2, .reveal h3, .reveal p, .reveal ul, .reveal li {
                font-family: 'Raleway', sans-serif;
            }
            .reveal h1 {
                font-size: 28px; /* Increased font size */
                text-transform: uppercase; /* Uppercase only for first slide */
            }
            .reveal h2 {
                font-size: 26px; /* Increased font size */
            }
            .reveal h3 {
                font-size: 24px; /* Increased font size */
                margin-top: 5px;
            }
            .reveal p {
                font-size: 20px; /* Increased font size */
            }
            .reveal ul {
                list-style: none;
                padding-left: 20px;
            }
            .reveal li {
                margin-bottom: 10px;
                font-size: 20px; /* Increased font size */
                color: #ffffff; /* Brighter text color for readability */
            }
            .centered-heading {
                text-align: center; /* Center-align the heading */
            }
            .video-container {
                display: flex;
                justify-content: center;
                align-items: center;
                gap: 20px; /* Add space between the videos */
            }
            .video-container video {
                width: 600px; /* Set a fixed width to make the videos larger */
                height: auto; /* Maintain aspect ratio */
            }
            .caption {
                text-align: center;
                font-size: 18px;
                color: #ffffff; /* Brighter text color for readability */
            }
            #particles-js {
                position: fixed;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                z-index: 0;
                background: linear-gradient(135deg, #001f3f, #0074D9, #39CCCC);
            }
            .image-container {
                display: flex;
                justify-content: flex-end; /* Align image to the right */
                margin-top: -50px; /* Adjust margin to move image up */
            }
            .image-container img {
                width: 300px; /* Adjust image size as needed */
                height: auto;
                margin-left: 20px; /* Add margin to left of image to separate it from text */
            }
            .top-right-container {
                position: absolute;
                top: 0;
                right: 20px;
                text-align: center;
                transform: translateY(-40%); /* Move the image much higher */
            }
            .top-right-container img {
                width: 300px; /* Adjust image size as needed */
                height: auto;
            }
            .top-right-container .caption {
                margin-top: 10px;
            }
            .bottom-right-container {
                position: absolute;
                top: 0;
                right: 20px;
                text-align: center;
                transform: translateY(40%); /* Move the image much higher */
            }
            
            .bottom-right-container img {
                width: 300px; /* Adjust image size as needed */
                height: auto;
            }
            .bottom-right-container .caption {
                margin-top: 10px;
            }
        </style>
    </head>
    <body>
        <div id="particles-js"></div>
        <div class="reveal">
            <div class="slides">
                <section>
                    <h1>Understanding intelligent predictive systems through a comparative analysis of latent spaces</h1>
                    <h3>SURF Project by Sam Fatehmanesh</h3>
                    <h3>Advised by James Gornet and Matt Thomson</h3>
                    <h3>Thomson Laboratory</h3>
                    <h3>Caltech</h3>
                </section>
                <section>
                    <h2>Presentation Outline</h2>
                    <ul>
                        <li>Research Question and Background</li>
                        <li>Research Overview</li>
                        <li>Future Research</li>
                        <li>Acknowledgements and References</li>
                    </ul>
                </section>
                <section>
                    What is prediction?
                </section>
                <section>
                    <h1>Prediction is everywhere</h1>
                    <div class="top-right-container">
                        <img src="wolf.jpg" alt="wolf">
                    </div>
                    <div class="bottom-right-container">
                        <img src="bee.webp" alt="bee">
                    </div>
                </section>
                <section>
                    <h1>The hardware of prediction</h1>
                    <div class="top-right-container">
                        <img src="cortex.jpg" alt="cortex">
                    </div>
                </section>
                <section>
                    <h2>Is prediction performed similarly across biological and artificial systems?</h2>
                </section>
                <section>
                    <h1>Understanding prediction enables better predictions</h1>
                </section>
                <section>
                    <h1>Research Overview</h1>
                    <ul>
                        <li>Predictor Systems
                            <ul>
                                <li>In Vitro Optically Interfaced Neuron Culture (In Progress)</li>
                                <li>In Vivo mouse visual cortex (Provided by Allen Brain Observatory)</li>
                                <li>In Silico Artificial Neural Network (ANN) predictor (Completed)</li> 
                            </ul>
                        </li>
                        <li>Intermediate prediction representations
                            <ul>
                                <li>The intermediate representations/latents of the predictors may hint at how prediction is being performed</li>
                                <li>ANN intermediate latents extracted from sequential model</li>
                                <li>In vitro neuron culture latents extracted with calcium imaging</li>
                                <li>In vivo mouse visual cortex latents provided by Allen Brain Observatory</li>
                            </ul>
                        </li>
                        <li>Comparative Analysis of Latents
                            <ul>
                                <li>Linear transform between latent spaces</li>
                                <li>Feature identifications between latents and objective via non-linear transforms</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h1 class="centered-heading">Artificial Prediction Example</h1>
                    <div class="video-container">
                        <div>
                            <video controls>
                                <source src="vid1.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div class="caption">True Observations</div>
                        </div>
                        <div>
                            <video controls>
                                <source src="vid2.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div class="caption">Predicted Observations</div>
                        </div>
                    </div>
                </section>
                <section>
                    <h1>Embodied Neuron Culture Overview</h1>
                    <ul>
                        <li>Requirements
                            <ul>
                                <li>Arbitrary read-write access</li>
                                <li>Long-Term Culture Survival</li>
                                <li>Plasticity and Learning</li>
                            </ul>
                        </li>
                        <li>Culture Development
                            <ul>
                                <li>Optogenetic rat line</li>
                                <li>Utilizing genetically encoded opsins and biosensors, e.g., GCaMP, ChRger2</li>
                                <li>Optogenetics allows for signal input and output from neurons in rat cortex neurons</li>
                                <li>Rat brain neurons extracted and cultured</li>
                            </ul>
                        </li>
                        <li>Optical Interface
                            <ul>
                                <li>CMOS sensor for neuron spike output (Guo)</li>
                                <li>microOLED display for neuron spike input</li>
                            </ul>
                        </li>
                        <li>Virtual Environment
                            <ul>
                                <li>Neuron Culture training performed with periodic signal rewards and random signal punishments (Kagan)</li>
                                <li>Improving predictions rewarded</li>
                                <li>Worsening predictions punished</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <h1>Neural Culture Interaction System</h1>
                    <ul>
                        <li>Requirements
                            <ul> 
                                <li>Prediction of Neural Culture Activity</li>
                                <li>Arbitrary Control of Neural Culture</li>
                            </ul>
                        </li>
                        <li>Methods used
                            <ul> 
                                <li>Prediction achieved via convolutional neural networks and Mamba sequential predictor</li>
                                <li>Control to be achieved via soft actor-critic reinforcement learning algorithm</li>
                            </ul>
                        </li>
                    </ul>
                    <div class="video-container">
                        <div>
                            <video controls>
                                <source src="true_sim.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div class="caption">True Observations</div>
                        </div>
                        <div>
                            <video controls>
                                <source src="pred_sim.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div class="caption">Predicted Observations</div>
                        </div>
                    </div>
                </section>
                <section>
                    <h1>Optical Neural Interface (ONI) v0</h1>
                    <ul>
                        <li>Interface Hardware Rough Specs
                            <ul>
                                <li>Sony OV2311 CMOS sensor for neural output recording</li>
                                <li>Sony OLED ECX337AF display for neural input stimulation</li>
                                <li>Dichroic mirror enables simultaneous read-write</li>
                            </ul>
                        </li>
                    </ul>
                    <div class="top-right-container">
                        <img src="cad.png" alt="CAD Image">
                        <div class="caption">ONI v0 CAD</div>
                    </div>
                </section>
                <section>
                    <h1>Acknowledgements</h1>
                    <ul>
                        <li>James Gornet</li>
                        <li>Matt Thomson</li>
                        <li>Daniel Wagenaar</li>
                        <li>Caltech SFP Office</li>
                    </ul>
                </section>
                <section>
                    <h1>References</h1>
                    <ul>
                        <li>
                            <ul>
                                <li>Gornet, J. A., & Thomson, M. (2023). Automated construction of cognitive maps with predictive coding. bioRxiv, 2023-09.</li>
                                <li>Guo, C., Blair, G. J., Sehgal, M., Sangiuliano Jimka, F. N., Bellafard, A., Silva, A. J., ... & Aharoni, D. (2023). Miniscope-LFOV: A large-field-of-view, single-cell-resolution, miniature microscope for wired and wire-free imaging of neural dynamics in freely behaving animals. Science advances, 9(16), eadg3918.</li>        
                                <li>Kagan, B. J., Kitchen, A. C., Tran, N. T., Habibollahi, F., Khajehnejad, M., Parker, B. J., ... & Friston, K. J. (2022). In vitro neurons learn and exhibit sentience when embodied in a simulated game-world. Neuron, 110(23), 3952-3969.</li>
                                <li>Grill, J. B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., ... & Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems, 33, 21271-21284.</li>
                            </ul>
                        </li>
                    </ul>
                </section>
            </div>
        </div>
    
        <script src="dist/reveal.js"></script>
        <script src="plugin/notes/notes.js"></script>
        <script src="plugin/markdown/markdown.js"></script>
        <script src="plugin/highlight/highlight.js"></script>
        <script>
            Reveal.initialize({
                hash: true,
                plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
            });
        </script>
        <script>
            particlesJS("particles-js", {
                particles: {
                    number: { value: 80, density: { enable: true, value_area: 800 } },
                    color: { value: "#ffffff" },
                    shape: {
                        type: "circle",
                        stroke: { width: 0, color: "#000000" },
                        polygon: { nb_sides: 5 },
                        image: { src: "img/github.svg", width: 100, height: 100 }
                    },
                    opacity: {
                        value: 0.5,
                        random: false,
                        anim: { enable: false, speed: 1, opacity_min: 0.1, sync: false }
                    },
                    size: {
                        value: 3,
                        random: true,
                        anim: { enable: false, speed: 40, size_min: 0.1, sync: false }
                    },
                    line_linked: {
                        enable: true,
                        distance: 150,
                        color: "#ffffff",
                        opacity: 0.4,
                        width: 1
                    },
                    move: {
                        enable: true,
                        speed: 6,
                        direction: "none",
                        random: false,
                        straight: false,
                        out_mode: "out",
                        bounce: false,
                        attract: { enable: false, rotateX: 600, rotateY: 1200 }
                    }
                },
                interactivity: {
                    detect_on: "canvas",
                    events: {
                        onhover: { enable: true, mode: "repulse" },
                        onclick: { enable: true, mode: "push" },
                        resize: true
                    },
                    modes: {
                        grab: { distance: 400, line_linked: { opacity: 1 } },
                        bubble: { distance: 400, size: 40, duration: 2, opacity: 8, speed: 3 },
                        repulse: { distance: 200, duration: 0.4 },
                        push: { particles_nb: 4 },
                        remove: { particles_nb: 2 }
                    }
                },
                retina_detect: true
            });
        </script>
    </body>    
</html>
